{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "aUfWuhdwrWJR"
      },
      "source": [
        "# Rozdzielczość obrazu. Interpolacja.\n",
        "\n",
        "## Cel zajęć:\n",
        "\n",
        "* zapoznanie z pojęciem rozdzielczości przestrzennej (rozmiaru obrazu),\n",
        "* metody interpolacji najbliższego sąsiada oraz dwuliniowa,\n",
        "* zapoznanie z pojęciem rozdzielczości dpi (ang. dots per inch),\n",
        "* zapoznanie z pojęciem rozdzielczości  poziomów jasności (dla obrazów w skali szarości),\n",
        "* zadanie domowe: interpolacja dwusześcienna.\n",
        "\n",
        "## Rodzielczość przestrzenna\n",
        "\n",
        "Dyskretna reprezentacja obrazu to zwykle macierz dwu (N x M - obraz w skali szarości) lub trójwymiarowa (N x M x 3 - obraz kolorowy).\n",
        "Przez rozdzielczość przestrzenną rozumie się liczbę pikseli z których składa się obraz.\n",
        "Przykładowo rozdzielczość VGA to  640 x 480, Full HD to 1920 x 1080, a 4K to 3840 x 2160.\n",
        "Rozdzielczość obrazu można modyfikować (zwiększać/zmniejszać), co nazywa się skalowaniem obrazu.\n",
        "Warto wiedzieć, że zwiększenie rozdzielczości obrazu nie zwiększa ilości informacji, a jedynie liczbę pikseli (w sensie \"lepiej nie będzie\").\n",
        "Ponadto skalowanie zawsze wprowadza pewne zniekształcenia, nawet przy zmniejszaniu rozmiaru.\n",
        "\n",
        "W ramach niniejszego ćwiczenia zapoznamy się z metodami interpolacji, które są podstawą takich operacji jak: przybliżanie (zoom), zmiana rozdzielczości, rotacja obrazu, czy też korekcje geometryczne.\n",
        "Jako przykład posłuży nam zmiana rozdzielczości, czyli inaczej mówiąc przepróbkowanie obrazu.\n",
        "Dla przypomnienia - interpolacja to wykorzystanie znanych danych (wartości dla tzw. punktów węzłowych) do określania wartości w nieznanych lokalizacjach.\n",
        "\n",
        "Zacznijmy od prostego przykładu.\n",
        "Mamy obraz o rozdzielczości 500 x 500 pikseli, a chcemy go powiększyć do 750 x 750 pikseli -- tj. o~współczynnik 1,5.\n",
        "Wyobraźmy sobie zatem, że dysponujemy siatką 750 x 750 o takim samym \"rozmiarze\" pojedynczego piksela jak obraz oryginalny.\n",
        "Następnie siatkę tą ,,ścieśniamy'', tak aby miała rozmiar 500 x 500.\n",
        "W rezultacie otrzymana siatka będzie miała mniejszy rozmiar pojedynczego piksela niż obraz oryginalny.\n",
        "Schematycznie przedstawiono to na poniższym rysunku.\n",
        "\n",
        "![Ilustracja interpolacji](https://raw.githubusercontent.com/vision-agh/poc_sw/master/05_Resolution/img/interEx57.png)\n",
        "\n",
        "\n",
        "Pokazuje on przykład interpolacji: a) obraz 5x5, b) oraz 7x7, c) obraz 7x7 zmiejszony do 5x5.\n",
        "\n",
        "\n",
        "Chcemy teraz poszczególnym elementom nowej siatki przyporządkować piksele z obrazu wejściowego.\n",
        "Jedną z możliwości jest poszukanie \"najbliższego\" piksela w oryginalnym obrazie i wzięcie jego wartości.\n",
        "Przykład takiego postępowania zaprezentowano na  poniższym rysunku.\n",
        "\n",
        "![Ilustracja najbliższego sąsiada](https://raw.githubusercontent.com/vision-agh/poc_sw/master/05_Resolution/img/inteNNEx.png)\n",
        "\n",
        "Kilka słów wyjasnienia.\n",
        "Kolorem ciemnoszarym oznaczono siatkę 5x5, a czarnym 7x7 (już po przeskalowaniu).\n",
        "Nasze zadanie sprowadza się do znalezienia dla każdej kropki czarnej (umowny środek piksela), najbliżej leżącej kropki szarej - oznaczono to dla pierwszych trzech wierzszy obrazu liniami.\n",
        "\n",
        "Po zrealizowaniu powyższego kroku dla całego obrazu wykonujemy \"rozciągniecie\" do rozdzielczości 750 x 750.\n",
        "W ten sposób uzyskujemy finalny efekt zmiany rozdzielczości.\n",
        "\n",
        "## Interpolacja metodą najbliższego sąsiada\n",
        "\n",
        "Takie postępowanie określa się mianem **interpolacji metodą najbliższego sąsiada** (ang. *nearest neighbour interpolation*).\n",
        "W ramach pierwszego etapu ćwiczenia zaimplementujemy to podejście.\n",
        "\n",
        "1. Ładujemy potrzebne biblioteki, pobieramy obrazy z repozytorium, wczytujemy jeden z obrazów testowych (*parrot.bmp*) i wyświetlamy go:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "aQr5EwbirWJV"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "\n",
        "# Load required files\n",
        "if not os.path.exists(\"parrot.bmp\") :\n",
        "    !wget https://raw.githubusercontent.com/vision-agh/poc_sw/master/05_Resolution/parrot.bmp --no-check-certificate\n",
        "if not os.path.exists(\"clock.bmp\") :\n",
        "    !wget https://raw.githubusercontent.com/vision-agh/poc_sw/master/05_Resolution/clock.bmp --no-check-certificate\n",
        "if not os.path.exists(\"chessboard.bmp\") :\n",
        "    !wget https://raw.githubusercontent.com/vision-agh/poc_sw/master/05_Resolution/chessboard.bmp --no-check-certificate\n",
        "if not os.path.exists(\"lena.bmp\") :\n",
        "    !wget https://raw.githubusercontent.com/vision-agh/poc_sw/master/05_Resolution/lena.bmp --no-check-certificate\n",
        "if not os.path.exists(\"firetruck.jpg\") :\n",
        "    !wget https://raw.githubusercontent.com/vision-agh/poc_sw/master/05_Resolution/firetruck.jpg --no-check-certificate\n",
        "\n",
        "\n",
        "parrot = cv2.imread('parrot.bmp')           # Read image\n",
        "parrot = cv2.cvtColor(parrot, cv2.COLOR_BGR2GRAY) # Convert to RGB\n",
        "\n",
        "chessboard = cv2.imread('chessboard.bmp')           # Read image\n",
        "chessboard= cv2.cvtColor(chessboard, cv2.COLOR_BGR2GRAY) # Convert to RGB\n",
        "\n",
        "clock= cv2.imread('clock.bmp')           # Read image\n",
        "clock = cv2.cvtColor(clock, cv2.COLOR_BGR2GRAY) # Convert to RGB\n",
        "# Display\n",
        "plt.figure(figsize=(parrot.shape[0]/100,parrot.shape[1]/100), dpi=200)\n",
        "plt.imshow(parrot, cmap =\"gray\")\n",
        "plt.xticks([]), plt.yticks([])  # Hides the graph ticks and x / y axis\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "b-y4TDTcrWJX"
      },
      "source": [
        "2. Definiujemy funkcję do interpolacji metodą najbliższego sąsiada.\n",
        "\n",
        "Jako argumenty wejściowe powinna ona przyjąć obraz oraz współczynniki skalowania w pionie i poziomie.\n",
        "Wyjściem powinien być natomiast obraz w nowej rozdzielczości.\n",
        "Wewnątrz należy:\n",
        "\n",
        "* odczytać wymiary obrazka wejściowego,\n",
        "* wyliczyć wymiary obrazka wyjściowego (tj. wymnożyć wymiary wejściowe przez skalę i zaokrąglić do liczb całkowitych),\n",
        "* utworzyć nowy obraz o ww. rozmiarze,\n",
        "* w pętli po nowym obrazie, dla każdego piksela, wykorzystując współczynniki skalowania, odnaleźć najbliższego sąsiada.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UlLTkutXrWJX"
      },
      "outputs": [],
      "source": [
        "# TODO: Do samodzielnej implemetantacji\n",
        "def neighbour_interpolation(image, f_scale, sc_scale):\n",
        "    x_size,y_size =image.shape\n",
        "    new_x = np.round(x_size*f_scale)\n",
        "    new_y = np.round(y_size*sc_scale)\n",
        "    new_x=int(new_x)\n",
        "    new_y=int(new_y)\n",
        "    n_image=np.zeros((new_x,new_y))\n",
        "    for k in range(new_x):\n",
        "        for m in range(new_y):\n",
        "            zm1=np.round(k/f_scale)\n",
        "            zm2=np.round(m/sc_scale)\n",
        "            if(int(zm1)<x_size and int(zm2)<y_size):\n",
        "                n_image[k,m]=image[int(zm1),int(zm2)]\n",
        "    return n_image\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnoSC3fyrWJY"
      },
      "source": [
        "3. Testujemy stworzoną funkcję:\n",
        "    * dla skali 1.5, 1.5 i obrazka *parrot*,\n",
        "    * dla 2.5, 2.5 - tu okaże się, że do kodu trzeba dopisać zabezpieczenie przed wyjściem poza zakres,\n",
        "    * dla niejednakowych skal np. 1.5 i 2.5,\n",
        "    * dla skal mniejszych od 1,\n",
        "    * dla niesymetrycznego obrazka *clock*,\n",
        "    * dla obrazka z szachownicą *chessboard*.\n",
        "\n",
        "Uwaga: proszę dla powyższych przypadków przygotować osobne sekcje kodu - tak, aby wyświetlały się wszystkie rozważane przypadki.\n",
        "\n",
        "Wykonana metoda jest bardzo prosta i szybka, ale wprowadza pewne niepożądane artefakty, w szczególnie źle odwzorowane są linie proste.\n",
        "Z drugiej strony sprawdza się w pewnych nietypowych przypadkach.\n",
        "Zostanie to zademonstrowane w dalszej części ćwiczenia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XfWpmM3ErWJY"
      },
      "outputs": [],
      "source": [
        "# TODO: Do samodzielnej implemetantacji\n",
        "image=neighbour_interpolation(parrot,1.5,1.5)\n",
        "plt.figure(figsize=(image.shape[0]/100,image.shape[1]/100), dpi=200)\n",
        "plt.imshow(image, cmap =\"gray\")\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image=neighbour_interpolation(parrot,2.5,2.5)\n",
        "plt.figure(figsize=(image.shape[0]/100,image.shape[1]/100), dpi=200)\n",
        "plt.imshow(image, cmap =\"gray\")\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ek7ul8AoHPZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image=neighbour_interpolation(parrot,1.5,2.5)\n",
        "plt.figure(figsize=(image.shape[0]/100,image.shape[1]/100), dpi=200)\n",
        "plt.imshow(image, cmap =\"gray\")\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HYNrymJ1HPyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image=neighbour_interpolation(parrot,0.75,0.75)\n",
        "plt.figure(figsize=(image.shape[0]/100,image.shape[1]/100), dpi=200)\n",
        "plt.imshow(image, cmap =\"gray\")\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_QK6_EGmHQpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image=neighbour_interpolation(clock,1.5,1.5)\n",
        "plt.figure(figsize=(image.shape[0]/100,image.shape[1]/100), dpi=200)\n",
        "plt.imshow(image, cmap =\"gray\")\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OGA9hdh7HQ2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image=neighbour_interpolation(chessboard,1.5,1.5)\n",
        "plt.figure(figsize=(image.shape[0]/100,image.shape[1]/100), dpi=200)\n",
        "plt.imshow(image, cmap =\"gray\")\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N0zxuSYTHRBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "mHR5MtqirWJZ"
      },
      "source": [
        "## Interpolacja dwuliniowa\n",
        "\n",
        "W praktyce, lepszym rozwiązaniem zwykle okazuje tzw. **interpolacja dwuliniowa** (ang. *bilinear interpolation*).\n",
        "Wykorzystuje ona informację o czterech najbliższych sąsiadach do określenia nowej wartości piksela.\n",
        "\n",
        "Jeśli przez $(i,j)$ oznaczymy współrzędne poszukiwanego piksela, a przez $I(i,j)$ jego jasność (składową w~odcieniach szarości) to jego wartość można obliczyć wykorzystując równanie:\n",
        "\\begin{equation}\n",
        "I(i,j) = a \\cdot i + b \\cdot j+ c \\cdot i \\cdot j + d\n",
        "\\tag{1}\n",
        "\\end{equation}\n",
        "gdzie: współczynniki $a,b,c,d$ można wyliczyć na podstawie czterech najbliższych sąsiadów.\n",
        "\n",
        "![Ilustracja dwuliniowej](https://raw.githubusercontent.com/vision-agh/poc_sw/master/05_Resolution/img/interABCD.png)\n",
        "\n",
        "Prześledźmy to na przykładzie z powyższego rysunku.\n",
        "Niech współrzędne poszczególnych punktów to $A = (j_1,i_1)$, $B = (j_1,i_2)$, $C= (j_2,i_2)$ oraz $D = (j_2,i_1)$.\n",
        "W pierwszej kolejności dokonujemy interpolacji wartości w punktach $AB$ i $CD$ -- czyli poziomo.\n",
        "Wychodząc od równania prostej otrzymujemy:\n",
        "\n",
        "\\begin{equation}\n",
        "f(AB) \\approx \\frac{i_2 - i}{i_2-i_1}f(A) + \\frac{i - i_1}{i_2-i_1}f(B)\n",
        "\\tag{2}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "f(CD) \\approx \\frac{i_2 - i}{i_2-i_1}f(D) + \\frac{i - i_1}{i_2-i_1}f(C)\n",
        "\\tag{3}\n",
        "\\end{equation}\n",
        "\n",
        "Następnie wykonujemy analogiczną interpolację w pionie:\n",
        "\\begin{equation}\n",
        "f(ABCD) \\approx \\frac{j_2 - j}{j_2-j_1}f(AB) + \\frac{j - j_1}{j_2-j_1}f(CD)\n",
        "\\tag{4}\n",
        "\\end{equation}\n",
        "\n",
        "Łącząc powyższe równania otrzymujemy:\n",
        "\\begin{equation}\n",
        "f(ABCD) \\approx \\frac{1}{(i_2 - i_1)(j_2-j_1)} ( f(A)(i_2-i)(j_2 - y) + f(B)(i-i_1)(j_2 - j) \\\\ + f(C)(i-i_1)(j-j_1) + f(D)(i_2-i)(j-j_1))\n",
        "\\tag{5}\n",
        "\\end{equation}\n",
        "gdzie zapis $f(X)$ oznacza wartość piksela w punkcie $X$.\n",
        "\n",
        "Rozważania można uprościć przyjmując, że narożniki rozpatrywanego kwadratu mają następujące współrzędne: $A = (0,0)$, $B = (0,1)$, $C= (1,1)$ oraz $D = (1,0)$.\n",
        "Wtedy powyższe równanie można zapisać:\n",
        "\\begin{equation}\n",
        "f(ABCD) \\approx f(A)(1-i)(1-j) + f(B)i(1-j) + f(C)ij + f(D)(1-i)j\n",
        "\\tag{6}\n",
        "\\end{equation}\n",
        "\n",
        "lub macierzowo:\n",
        "\\begin{equation}\n",
        "f(ABCD) \\approx \\begin{bmatrix}1 - i & i \\end{bmatrix} \\begin{bmatrix} f(A) & f(D) \\\\\\\\ f(B) & f(C)  \\end{bmatrix}   \\begin{bmatrix} 1-j \\\\\\\\ j  \\end{bmatrix}\n",
        "\\tag{7}\n",
        "\\end{equation}\n",
        "\n",
        "Uwaga.\n",
        "Nieco wbrew nazwie interpolacja dwuliniowa nie jest operacją liniową.\n",
        "W złożeniu dwóch operacji liniowych pojawia się człon $xy$.\n",
        "\n",
        "Warto dodać, że kolejny ``poziom wtajemniczenia'' to **interpolacja dwusześcienna** (ang. *bicubic interpolation*).\n",
        "Dana jest ona wzorem:\n",
        "\\begin{equation}\n",
        "I(i,j) = \\sum_{i=0}^{3} \\sum_{j=0}^{3} a_{ij} x^i y^j\n",
        "\\tag{8}\n",
        "\\end{equation}\n",
        "Jej implementacja stanowi zadanie domowe do bieżącego ćwiczenia.\n",
        "\n",
        "Trzy powyżej przedstawione metody bynajmniej nie wyczerpują tematu.\n",
        "Wystarczy choćby otworzyć stronę [wiki o skalowaniu](https://en.wikipedia.org/wiki/Image_scaling), by zobaczyć, że metod jest dużo więcej.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "DqZox2wQrWJZ"
      },
      "source": [
        "Wykorzystując powyższe równania zaimplementuj interpolację dwuliniową:\n",
        "* dobrym punktem wyjścia będzie stworzona funkcja do interpolacji metodą najbliższego sąsiada,\n",
        "* początek powinien być identyczny,\n",
        "* różnice rozpoczynają się w momencie obliczenia współrzędnych nowego piksela,\n",
        "* jeśli chcemy zastosować opisane powyżej wzory (w wariancie uproszczonym), to musimy wyliczyć współrzędne punktów $A,B,C,D$,\n",
        "* w pierwszym kroku obliczamy współrzędne $A$ tj. $(0,0)$ - należy do tego wykorzystać funkcję *floor* (np. $i_1 = floor(i / h_{scale})$).\n",
        "  Proszę ten krok odnieść do przedstawionego rysunku poglądowego,\n",
        "* obliczenie współrzędnych $B,C,D$ jest już proste i sprowadza się do operacji `+1`,\n",
        "* potrzebujemy jeszcze część ułamkową współrzędnych punktu $ABCD$ tj. $(i,j)$ - od ilorazu $i/h_{scale}$ należy odjąć wartość $i_1$\n",
        "* wykorzystując wyznaczone współrzędne, należy pobrać wartości jasności w punktach $A,B,C,D$, tj. $f(A),f(B),f(C),f(D)$, podstawić do odpowiedniego równania i wykonać interpolację.\n",
        "\n",
        "  Uwagi:\n",
        "* Tworzenie macierzy *np.array*, mnożenie macierzy *np.dot*. Przy tworzeniu macierzy proszę zwrócić uwagę na niezbędne nawiasy kwadratowe.\n",
        "* Przy próbie uruchomienia kodu pewnie okaże się, że wystąpi przekroczenie zakresu - należy dodać stosowne zabezpieczenie.\n",
        "\n",
        "Proszę dla interpolacji dwuliniowej wykonać takie same eksperymenty, jak dla  najbliższego sąsiada.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF7fPapMrWJa"
      },
      "outputs": [],
      "source": [
        "# TODO: Do samodzielnej implemetantacji\n",
        "def  bilinear_interpolation(image, f_scale,sc_scale):\n",
        "    x_size,y_size =image.shape\n",
        "    new_x = np.floor(x_size*f_scale)\n",
        "    new_y = np.floor(y_size*sc_scale)\n",
        "    new_x=int(new_x)\n",
        "    new_y=int(new_y)\n",
        "    n_image=np.zeros((new_x,new_y))\n",
        "    for i in range(new_x):\n",
        "        for j in range(new_y):\n",
        "          i_n=i/f_scale\n",
        "          j_n=j/sc_scale\n",
        "          i1=int(np.floor(i_n))     \n",
        "          j1=int(np.floor(j_n))\n",
        "          i2=int(np.floor(i_n+1))\n",
        "          j2=int(np.floor(j_n+1))\n",
        "          if i2>=x_size:\n",
        "             i2=i2-1\n",
        "          if j2>=y_size:\n",
        "             j2=j2-1\n",
        "          if i1==i2: \n",
        "             i1=i1-1\n",
        "          if j1==j2: \n",
        "             j1=j1-1\n",
        "          A=image[i1,j1]\n",
        "          B=image[i1,j2]\n",
        "          C=image[i2,j2]\n",
        "          D=image[i2,j2]\n",
        "          f_AB=A*((j2-j_n)/(j2-j1))+B*((j_n-j1)/(j2-j1))\n",
        "          f_CD=C*((j2-j_n)/(j2-j1))+D*((j_n-j1)/(j2-j1))\n",
        "          f_ABCD=f_AB*((i2-i_n)/(i2-i1))+f_CD*((i_n-i1)/(i2-i1))\n",
        "          n_image[i,j]=np.floor(f_ABCD)\n",
        "    return n_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHKXE4I9rWJa"
      },
      "outputs": [],
      "source": [
        "#TODO Do samodzielnej implementacji\n",
        "image=bilinear_interpolation(parrot,1.5,1.5)\n",
        "plt.figure(figsize=(image.shape[0]/100,image.shape[1]/100), dpi=200)\n",
        "plt.imshow(image, cmap =\"gray\")\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image=bilinear_interpolation(parrot,2.5,2.5)\n",
        "plt.figure(figsize=(image.shape[0]/100,image.shape[1]/100), dpi=200)\n",
        "plt.imshow(image, cmap =\"gray\")\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kVzFFrRPNRBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image=bilinear_interpolation(parrot,1.5,2.5)\n",
        "plt.figure(figsize=(image.shape[0]/100,image.shape[1]/100), dpi=200)\n",
        "plt.imshow(image, cmap =\"gray\")\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g7nuMRG7OHHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image=bilinear_interpolation(parrot,0.75,0.75)\n",
        "plt.figure(figsize=(image.shape[0]/100,image.shape[1]/100), dpi=200)\n",
        "plt.imshow(image, cmap =\"gray\")\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FWqTzylwOH3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image=bilinear_interpolation(clock,1.5,1.5)\n",
        "plt.figure(figsize=(image.shape[0]/100,image.shape[1]/100), dpi=200)\n",
        "plt.imshow(image, cmap =\"gray\")\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hzEipu0HOILf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image=bilinear_interpolation(chessboard,1.5,1.5)\n",
        "plt.figure(figsize=(image.shape[0]/100,image.shape[1]/100), dpi=200)\n",
        "plt.imshow(image, cmap =\"gray\")\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dXWEciuPOJZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "_P0gvtKzrWJb"
      },
      "source": [
        "## Interpolacja w OpenCV\n",
        "\n",
        "W OpenCV dostępna jest funkcja `resize`, która służy do zmiany rozmiaru obrazka.\n",
        "Składnia jest następująca `dst = cv2.resize(\tsrc, dsize[, dst[, fx[, fy[, interpolation]]]] )`, gdzie `det` to obraz wynikowy, `src` obraz źródłowy, `dsize` rozmiar docelowy (ew. można podać współczynniki skalowania dla poszczególnych osi: `fx,fy`), `interpolation` metoda interpolacji.\n",
        "Metod podstawowych dostępnych jest 5:\n",
        "- najbliższego sąsiada - ` cv2.INTER_NEAREST`,\n",
        "- dwuliniowa - ` cv2.INTER_LINEAR`,\n",
        "- dwukubiczna - ` cv2.INTER_CUBIC`,\n",
        "- *area* - ` cv2.INTER_AREA`,\n",
        "- *lanczos4* - ` cv2.INTER_LANCZOS4`.\n",
        "\n",
        "Przeprowadzimy następujący eksperyment: obraz (o większej niż dotąd rozdzielczości) przeskalujemy każdą z metod -- zwiększymy i zmniejszymy jego rozdzielczość. Dodamy też pomiar czasu realizacji obliczeń.\n",
        "\n",
        "Obraz: TODO\n",
        "\n",
        "\n",
        "Proszę stworzyć funkcję, która jako argumenty przyjmuje obraz oraz dwa współczynniki skalujące, a wewnątrz przeprowadzone zostaną interpolacje, pomiar czasu oraz wizualizacja (można wypisać czas w tytule rysunku).\n",
        "\n",
        "Pomiar czasu:\n",
        "```{python}\n",
        "from timeit import default_timer as timer\n",
        "start = timer()\n",
        "# ...\n",
        "end = timer()\n",
        "print(end - start)\n",
        "```\n",
        "\n",
        "Wykonaj eksperyment dla kilku różnych skal, przeanalizuj czasy obliczeń."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xacfa2pOrWJb"
      },
      "outputs": [],
      "source": [
        "from timeit import default_timer as timer\n",
        "firetruck=cv2.imread(\"firetruck.jpg\")\n",
        "firetruck = cv2.cvtColor(firetruck, cv2.COLOR_BGR2GRAY)\n",
        "#TODO Do samodzielnej implementacji\n",
        "interpolations=[cv2.INTER_NEAREST,cv2.INTER_LINEAR,cv2.INTER_CUBIC,cv2.INTER_AREA,cv2.INTER_LANCZOS4]\n",
        "def ex(image,first_sc,second_sc):\n",
        "  x,y=image.shape\n",
        "  new_x=int(x*first_sc)\n",
        "  new_y=int(y*second_sc)\n",
        "  for k in interpolations:\n",
        "    start=timer()\n",
        "    image_resize=cv2.resize(image,(new_x,new_y),k)\n",
        "    end=timer()\n",
        "    time=end-start\n",
        "    plt.figure(figsize=(x/150,y/150))\n",
        "    plt.imshow(image_resize, cmap =\"gray\")\n",
        "    plt.title(\"czas obliczania: {}\".format(time))\n",
        "    plt.xticks([]), plt.yticks([])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex(firetruck,2.0,2.0)"
      ],
      "metadata": {
        "id": "Goo9_WqyW5rG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex(firetruck,0.75,0.75)\n",
        "\n",
        "#można tutaj zauważyć,że zmniejszanie zachodzi szybciej niż powiększanie"
      ],
      "metadata": {
        "id": "onYB5LNQW6Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "RWJkUkGErWJb"
      },
      "source": [
        "## Rozdzielczość (dpi)\n",
        "\n",
        "Omówioną wcześniej rozdzielczość przestrzenną (rozmiar) należy utożsamiać z rozmiarem macierzy w której zapisany jest obraz.\n",
        "W tym ujęciu rozmiar pojedynczego piksela nie ma specjalnego znaczenia.\n",
        "Problem pojawia się, kiedy obraz trzeba wyświetlić lub wydrukować.\n",
        "Wtedy pojedynczy piksel staje się ,,obiektem fizycznym'' i musi mieć swój rozmiar (wysokość/szerokość/powierzchnię).\n",
        "\n",
        "Parametr dpi (ang. *dots per inch*) określa liczbę kropek (pikseli), która mieści się na jednym calu (25,4 mm) długości/szerokości.\n",
        "Dopiero kombinacja rozmiaru i rozdzielczości określa nam rzeczywisty rozmiar obrazu jaki uzyskamy na wydruku.\n",
        "\n",
        "Dpi staje się istotne w przypadku drukowania, gdyż wyświetlanie na monitorze odbywa się zazwyczaj 1 piksel obrazka = 1 piksel na monitorze (w przypadku maksymalnej rozdzielczości wspieranej przez monitor), ew. następuje automatyczne skalowanie.\n",
        "\n",
        "Wpływ rozdzielczości można zademonstrować w następujący sposób:\n",
        "- wczytaj obraz *lena.bmp*.  Ma on rozmiar $512 \\times 512$.\n",
        "- wykorzystując funkcję `imresize` stwórz obrazy o rozmiarach $256 \\times 256$, $128 \\times 128$, $64 \\times 64$ - metoda interpolacji jest w tym wypadku mniej istotna.\n",
        "- wyświetl obrazy wymuszając zachowanie na ekranie wejściowej rozdzielczości $512 \\times 512$. W przypadku biblioteki *matplotlib* ta funkcjonalność jest domyślna.\n",
        "\n",
        "Proszę zaobserwować co dzieję się z obrazkiem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "pgni8WPrrWJc"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "lena= cv2.imread('lena.bmp')           # Read image\n",
        "lena = cv2.cvtColor(lena, cv2.COLOR_BGR2GRAY) # Convert to RGB\n",
        "lena_256=cv2.resize(lena,(256,256),cv2.INTER_NEAREST)\n",
        "lena_128=cv2.resize(lena,(128,128),cv2.INTER_NEAREST)\n",
        "lena_64=cv2.resize(lena,(64,64),cv2.INTER_NEAREST)\n",
        "\n",
        "plt.imshow(lena, cmap =\"gray\")\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.imshow(lena_256, cmap =\"gray\")\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(lena_128, cmap =\"gray\")\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(lena_64, cmap =\"gray\")\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()\n",
        "\n",
        "#jakość obrazka stopniowo spada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ahLs2FforWJc"
      },
      "source": [
        "## Liczba poziomów jasności\n",
        "\n",
        "Dla obrazów w skali szarości pojedynczy piksel zwykle zapisuje się na 8 bitach, co daje 256 rozróżnialnych poziomów szarości.\n",
        "Dla większości zastosowań wartość ta jest wystarczająca (choć są kamery o wyjścu 12 lub 16 bitów).\n",
        "Jednak oko ludzkie nie potrafi rozróżnić wszystkich 256 poziomów jasności (jest za mało czułe).\n",
        "Zazwyczaj człowiek rozróżnia 20-30 poziomów szarości (to ile i jakie dokładnie rozróżnia, zależy od konkretnego oświetlenia sceny i cech osobniczych).\n",
        "\n",
        "W poniższych krokach zademonstrujemy omówione zjawisko:\n",
        "- wczytaj (użyj) obrazu _lena_,\n",
        "- wykorzystując znaną funkcję `normalize` zmień liczbę poziomów szarości z 0-255 na:\n",
        "    * 0-31\n",
        "    * 0-15\n",
        "    * 0-7\n",
        "    * 0-3\n",
        "    * 0-1 (binaryzacja)\n",
        "- rezultaty wyświetl na wspólnym rysunku.\n",
        "\n",
        "Podpowiedzi:\n",
        "- trzeba przygotować tablice na obrazki np, `I_31 = np.zeros(I.shape,'uint8')`,\n",
        "- prawidłowe użycie funkcji normalize `cv2.normalize(I,I_31,0,31,cv2.NORM_MINMAX)`,\n",
        "- przykładowe wyświetlanie `axsHist[0,1].imshow(I, 'gray', vmin=0, vmax=31)`.\n",
        "\n",
        "Czy rezultaty eksperymentu pasują do teorii o rozpoznawaniu przez człowieka ograniczonego zakresu poziomów jasności?\n",
        "Wizualne porównanie których obrazów o tym świadczy ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2xMnikSJrWJd"
      },
      "outputs": [],
      "source": [
        "I = cv2.imread('lena.bmp')\n",
        "I = cv2.cvtColor(I, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "I_31 = np.zeros(I.shape,'uint8')\n",
        "I_15 = np.zeros(I.shape,'uint8')\n",
        "I_7 = np.zeros(I.shape,'uint8')\n",
        "I_3 = np.zeros(I.shape,'uint8')\n",
        "I_1 = np.zeros(I.shape,'uint8')\n",
        "\n",
        "cv2.normalize(I,I_31,0,31,cv2.NORM_MINMAX)\n",
        "cv2.normalize(I,I_15,0,15,cv2.NORM_MINMAX)\n",
        "cv2.normalize(I,I_7,0,7,cv2.NORM_MINMAX)\n",
        "cv2.normalize(I,I_3,0,3,cv2.NORM_MINMAX)\n",
        "cv2.normalize(I,I_1,0,1,cv2.NORM_MINMAX)\n",
        "\n",
        "fig, axs=plt.subplots(1,5,figsize=(15,15))\n",
        "axs[0].imshow(I_31, 'gray', vmin=0, vmax=31)\n",
        "axs[0].set_title('0-31')\n",
        "axs[1].imshow(I_15, 'gray', vmin=0, vmax=15)\n",
        "axs[1].set_title('0-15')\n",
        "axs[2].imshow(I_7, 'gray', vmin=0, vmax=7)\n",
        "axs[2].set_title('0-7')\n",
        "axs[3].imshow(I_3, 'gray', vmin=0, vmax=3)\n",
        "axs[3].set_title('0-3')\n",
        "axs[4].imshow(I_1, 'gray', vmin=0, vmax=1)\n",
        "axs[4].set_title('0-1')\n",
        "for i in range(5):\n",
        "  axs[i].axis('off')\n",
        "\n",
        "\n",
        "#różnice pomiędzy pierwszym i drugim przypadkiem są niewielkie"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "05_resolution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}